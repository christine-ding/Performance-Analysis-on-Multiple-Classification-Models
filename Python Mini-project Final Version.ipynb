{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Python Mini-project</h1>\n",
    "<br>\n",
    "<h2>Predictive Analytics using Python (CIS432)</h2>\n",
    "</center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-project 1\n",
    "\n",
    "__Goal:__ The goal of this assignment is to conduct a study that compares the performance of various classification algorithms on a variety of datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Datasets:__ The folder data contains 98 publicly available datasets from the UCI machine learning repository ([link](http://archive.ics.uci.edu/ml/index.php)). These datasets were collected and converted to a standard format by Dunn and Bertsimas (for more details see [link1](https://github.com/JackDunnNZ/uci-data) and [link2](http://jack.dunn.nz/papers/OptimalClassificationTrees.pdf)):\n",
    "* Each dataset is stored in a separate folder\n",
    "* Each folder contains a datafile and the configuration file config.ini specifying the data format\n",
    "- Data files are stored in csv format and their names either end with \".orig\" or at \".custom\". If both files exist in a folder, use the file ending with \".custom\"\n",
    "- Each config.ini file contains information about a dataset: \n",
    "    - separator: the character used to separate columns in the respective csv file\n",
    "    - header_lines: the number of rows to be skipped in the datafile as these contain some information about the file but not data\n",
    "    - target_index: the column number of the output variable\n",
    "    - value_indices: the column numbers of the input variables\n",
    "    - categoric_indices: column numbers of categorical data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarks__:\n",
    "1. Notice that column numbering in the configuration files begins with 1 (versus 0 in Python)\n",
    "2. You may use the package [configparser](https://docs.python.org/3.7/library/configparser.html) to read and parse config.ini files\n",
    "3. The character \"?\" denotes a null value. After reading a data file, you may drop all lines that contain null values.\n",
    "4. Out of the 98 datasets, use only the 54 datasets whose name is stored in the file \"datasets_selection\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment__: compare the performance of the following classification algorithms on the 54 datasets: \n",
    "- Support vector machine, \n",
    "- Logistic Regression, \n",
    "- K-nearest neighbors, \n",
    "- Decision trees, \n",
    "- Quadratic discriminant analysis, \n",
    "- Random forests, and \n",
    "- AdaBoost\n",
    "\n",
    "\n",
    "Submit your solution as a jupyter notebook and include in your submission other files that may be needed to replicate your analysis. In addition, submit a report (at most 4 pages long) that discusses your methodology, key findings, as well as the limitations of your analysis. Compare the use of ML methods in this project against typical ML applications. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "import os\n",
    "\n",
    "def ConfigRead(file):\n",
    "    global name, head, sep, categoric, target, values\n",
    "    if file == \"breast-cancer-wisconsin\":\n",
    "        file = \"breast-cancer-wisconsin-original\"\n",
    "    \n",
    "    path = ('data/' + file + \"/config.ini\")\n",
    "    if os.path.isfile(path):\n",
    "        config.read(path)\n",
    "        name = config['info']['name']\n",
    "        head = int(config['info']['header_lines'])\n",
    "        sep = config['info']['separator']\n",
    "        categoric = config['info']['categoric_indices']\n",
    "        target = config['info']['target_index']\n",
    "        values = config['info']['value_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetData(file):\n",
    "    global df\n",
    "    if file == \"breast-cancer-wisconsin\":\n",
    "        file = \"breast-cancer-wisconsin-original\"\n",
    "    \n",
    "    d = str(max(os.listdir('data/' + file), key=len))\n",
    "    if sep == \"comma\":\n",
    "        df = pd.read_csv('data/' + file + '/' + d, sep=',', skiprows=head, header=None, na_values=[\"?\"])\n",
    "    elif sep == \";\":\n",
    "         df = pd.read_csv('data/' + file + '/' + d, sep=';', skiprows=head, header=None, na_values=[\"?\"])\n",
    "    else:\n",
    "        df = pd.read_csv('data/' + file + '/' + d, sep='\\s+', skiprows=head, header=None, na_values=[\"?\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataClean(df):\n",
    "    global train_x, test_x, train_y, test_y\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    new_target = int(target)-1 # y\n",
    "    value_list = [int(s)-1 for s in values.split(',')] # x\n",
    "\n",
    "    x = df.iloc[:, value_list] # extract x\n",
    "    y = df.loc[:, new_target] # extract y\n",
    "    \n",
    "    if categoric != '':\n",
    "        categoric_list = [int(s)-1 for s in categoric.split(',')] # categorical x\n",
    "        x_new = pd.get_dummies(x, columns= categoric_list, drop_first=True) # Categorical Transform X\n",
    "    else:\n",
    "        x_new = x\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y_new = encoder.fit_transform(y) # Categorical Transform Y\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x_new, y_new, test_size=0.2, random_state=1)\n",
    "    return train_x, test_x, train_y, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def RamdomForest(train_x,train_y):\n",
    "    global new_rfc\n",
    "    rfc = RandomForestClassifier()\n",
    "    param_grid = {'n_estimators': [10,50,100],'max_features': ['auto', 'sqrt', 'log2']}\n",
    "    \n",
    "    grid_search = GridSearchCV(rfc, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_rfc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def LogisticsRegression(train_x,train_y):\n",
    "    global new_lr\n",
    "    lr = LogisticRegression()\n",
    "    param_grid = {'C': [10,50,100]}\n",
    "    \n",
    "    grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_lr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "def AdaBoost(train_x,train_y):\n",
    "    global new_abc\n",
    "    abc = AdaBoostClassifier()\n",
    "    param_grid = {'n_estimators': range(3,10,1)}\n",
    "    \n",
    "    grid_search = GridSearchCV(abc, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_abc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN \n",
    "def KNN(train_x,train_y):\n",
    "    global new_knn\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_grid = {'n_neighbors': range(1,10,1),'weights':('uniform','distance')}\n",
    "    \n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_knn = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def DecisionTree(train_x,train_y):\n",
    "    global new_dt\n",
    "    dt = DecisionTreeClassifier()\n",
    "    param_grid = {'max_depth':range(10,60,10),'criterion':('gini','entropy')}\n",
    "    \n",
    "    grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_dt = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QDA\n",
    "def QDA(train_x,train_y):\n",
    "    global new_qda\n",
    "    qda = QuadraticDiscriminantAnalysis()\n",
    "    param_grid = {'tol':[0.0001,0.001,0.01]}\n",
    "    \n",
    "    grid_search = GridSearchCV(qda, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_qda = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "def svm(train_x,train_y):\n",
    "    global new_svm\n",
    "    svm = SVC(kernel='rbf')\n",
    "    param_grid = {'C':[0.02, 0.05, 0.1, 1]}\n",
    "    \n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(train_x,train_y)\n",
    "    new_svm = grid_search.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ModelSelect(train_x, train_y, test_x, test_y):\n",
    "        \n",
    "    svm(train_x, train_y)\n",
    "    LogisticsRegression(train_x, train_y)\n",
    "    KNN(train_x, train_y)\n",
    "    DecisionTree(train_x, train_y)\n",
    "    QDA(train_x, train_y)\n",
    "    RamdomForest(train_x, train_y)\n",
    "    AdaBoost(train_x, train_y)\n",
    "    \n",
    "    names = [\"SVM\", \"Logistic Regression\", \"KNN\", \"Decision Tree\", \"QDA\", \"Random Forest\", \"AdaBoost\"]\n",
    "    classifiers = [\n",
    "        new_svm,\n",
    "        new_lr,\n",
    "        new_knn,\n",
    "        new_dt,\n",
    "        new_qda,\n",
    "        new_rfc,\n",
    "        new_abc]\n",
    "    \n",
    "    results={}\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        train_predictions = clf.predict(test_x)\n",
    "        score = accuracy_score(test_y, train_predictions)\n",
    "        results.setdefault(name,[]).append(score)\n",
    "        df_results = pd.DataFrame.from_dict(results, orient='columns')\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.806358</td>\n",
       "      <td>0.927746</td>\n",
       "      <td>0.852601</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.893064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.582812</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.964646</td>\n",
       "      <td>0.893939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.549153</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>0.515254</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>0.535593</td>\n",
       "      <td>0.515254</td>\n",
       "      <td>0.569492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>0.740458</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.681034</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.807229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.487582</td>\n",
       "      <td>0.892810</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.950327</td>\n",
       "      <td>0.722876</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.482353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>0.924324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.981081</td>\n",
       "      <td>0.975676</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>0.983784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.940039</td>\n",
       "      <td>0.889749</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.941973</td>\n",
       "      <td>0.056093</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.943907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.908795</td>\n",
       "      <td>0.920738</td>\n",
       "      <td>0.823018</td>\n",
       "      <td>0.934853</td>\n",
       "      <td>0.798046</td>\n",
       "      <td>0.960912</td>\n",
       "      <td>0.834962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.693348</td>\n",
       "      <td>0.865840</td>\n",
       "      <td>0.897407</td>\n",
       "      <td>0.850056</td>\n",
       "      <td>0.866967</td>\n",
       "      <td>0.908681</td>\n",
       "      <td>0.190530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.992053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>0.936424</td>\n",
       "      <td>0.997351</td>\n",
       "      <td>0.936424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.813953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.852564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989927</td>\n",
       "      <td>0.908425</td>\n",
       "      <td>0.913004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AdaBoost  Decision Tree       KNN  Logistic Regression       QDA  \\\n",
       "0   1.000000       1.000000  1.000000             1.000000  1.000000   \n",
       "1   1.000000       1.000000  1.000000             1.000000  1.000000   \n",
       "2   0.824000       0.752000  0.872000             0.832000  0.896000   \n",
       "3   0.974545       0.992727  1.000000             0.992727  0.978182   \n",
       "4   0.793333       0.746667  0.740000             0.746667  0.440000   \n",
       "5   0.894737       0.964912  0.929825             0.964912  0.956140   \n",
       "6   0.970803       0.948905  0.985401             0.985401  1.000000   \n",
       "7   0.666667       0.564103  0.589744             0.743590  0.717949   \n",
       "8   0.806358       0.927746  0.852601             0.907514  0.170520   \n",
       "9   0.925000       0.993750  0.967187             0.978125  0.582812   \n",
       "10  0.935185       0.944444  0.935185             0.990741  0.925926   \n",
       "11  0.957447       0.957447  0.936170             0.957447  0.914894   \n",
       "12  0.131313       0.792929  0.984848             0.575758  0.893939   \n",
       "13  0.714286       0.714286  0.761905             0.761905  0.714286   \n",
       "14  0.549153       0.494915  0.515254             0.522034  0.535593   \n",
       "15  0.854962       0.854962  0.702290             0.877863  0.740458   \n",
       "16  0.696429       0.750000  0.678571             0.767857  0.696429   \n",
       "17  0.833333       0.972222  0.861111             0.972222  0.875000   \n",
       "18  0.846154       0.846154  0.692308             0.769231  0.615385   \n",
       "19  0.800000       0.800000  0.750000             0.850000  0.850000   \n",
       "20  0.725806       0.645161  0.725806             0.741935  0.741935   \n",
       "21  0.444444       0.925926  0.666667             0.407407  0.444444   \n",
       "22  0.500000       0.550000  0.466667             0.500000  0.483333   \n",
       "23  0.812500       0.750000  0.812500             0.812500  0.875000   \n",
       "24  0.404762       0.904762  0.857143             0.904762  0.428571   \n",
       "25  0.724138       0.655172  0.698276             0.758621  0.560345   \n",
       "26  0.845070       0.802817  0.830986             0.915493  0.830986   \n",
       "27  0.966667       0.966667  1.000000             0.933333  1.000000   \n",
       "28  0.837349       0.801205  0.777108             0.807229  0.807229   \n",
       "29  0.600000       0.760000  0.680000             0.600000  0.640000   \n",
       "30  0.617647       0.647059  0.911765             0.617647  1.000000   \n",
       "31  0.760000       0.760000  0.920000             0.920000  0.920000   \n",
       "32  0.487582       0.892810  0.988235             0.950327  0.722876   \n",
       "33  0.905405       0.927027  0.927027             0.929730  0.927027   \n",
       "34  0.983784       0.959459  0.981081             0.975676  0.983784   \n",
       "35  0.769231       0.794872  0.820513             0.846154  0.948718   \n",
       "36  0.766234       0.668831  0.766234             0.779221  0.740260   \n",
       "37  0.621622       0.540541  0.594595             0.702703  0.594595   \n",
       "38  0.800948       0.800948  0.834123             0.834123  0.668246   \n",
       "39  0.595238       1.000000  0.904762             1.000000  1.000000   \n",
       "40  0.940039       0.889749  0.936170             0.941973  0.056093   \n",
       "41  1.000000       1.000000  1.000000             1.000000  0.500000   \n",
       "42  0.908795       0.920738  0.823018             0.934853  0.798046   \n",
       "43  0.687500       0.812500  0.812500             0.687500  0.375000   \n",
       "44  0.750000       0.812500  0.875000             0.750000  0.500000   \n",
       "45  0.710000       0.635000  0.715000             0.750000  0.720000   \n",
       "46  0.693348       0.865840  0.897407             0.850056  0.866967   \n",
       "47  0.419355       0.645161  0.580645             0.645161  0.483871   \n",
       "48  0.840426       0.819149  0.851064             0.840426  0.148936   \n",
       "49  0.992053       1.000000  0.940397             0.952318  0.936424   \n",
       "50  0.837209       0.953488  0.953488             1.000000  0.976744   \n",
       "51  0.781250       0.958333  1.000000             0.989583  0.989583   \n",
       "52  0.852564       1.000000  0.989927             0.908425  0.913004   \n",
       "53  0.833333       0.972222  0.750000             0.944444  1.000000   \n",
       "\n",
       "    Random Forest       SVM  \n",
       "0        1.000000  1.000000  \n",
       "1        1.000000  1.000000  \n",
       "2        0.824000  0.864000  \n",
       "3        0.996364  1.000000  \n",
       "4        0.740000  0.726667  \n",
       "5        0.956140  0.631579  \n",
       "6        1.000000  0.992701  \n",
       "7        0.666667  0.717949  \n",
       "8        0.907514  0.893064  \n",
       "9        0.993750  0.925000  \n",
       "10       0.935185  0.925926  \n",
       "11       0.978723  0.978723  \n",
       "12       0.964646  0.893939  \n",
       "13       0.738095  0.476190  \n",
       "14       0.515254  0.569492  \n",
       "15       0.885496  0.503817  \n",
       "16       0.821429  0.714286  \n",
       "17       0.986111  0.958333  \n",
       "18       0.769231  0.769231  \n",
       "19       0.850000  0.850000  \n",
       "20       0.758065  0.774194  \n",
       "21       0.814815  0.814815  \n",
       "22       0.516667  0.500000  \n",
       "23       0.937500  0.875000  \n",
       "24       0.928571  0.119048  \n",
       "25       0.681034  0.724138  \n",
       "26       0.915493  0.887324  \n",
       "27       0.966667  0.966667  \n",
       "28       0.765060  0.807229  \n",
       "29       0.640000  0.600000  \n",
       "30       0.617647  0.676471  \n",
       "31       0.880000  0.920000  \n",
       "32       0.977778  0.482353  \n",
       "33       0.916216  0.924324  \n",
       "34       0.978378  0.983784  \n",
       "35       0.923077  0.820513  \n",
       "36       0.811688  0.642857  \n",
       "37       0.648649  0.702703  \n",
       "38       0.834123  0.810427  \n",
       "39       0.952381  0.952381  \n",
       "40       0.936170  0.943907  \n",
       "41       1.000000  1.000000  \n",
       "42       0.960912  0.834962  \n",
       "43       0.750000  0.812500  \n",
       "44       0.937500  0.375000  \n",
       "45       0.765000  0.705000  \n",
       "46       0.908681  0.190530  \n",
       "47       0.741935  0.483871  \n",
       "48       0.861702  0.851064  \n",
       "49       0.997351  0.936424  \n",
       "50       0.976744  0.813953  \n",
       "51       0.994792  0.937500  \n",
       "52       1.000000  0.946886  \n",
       "53       0.972222  0.388889  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "alldata = !cat datasets_selection\n",
    "alldata = [alldata[i][:-5] for i in range(54)]\n",
    "\n",
    "df_accuracy = pd.DataFrame()\n",
    "for i in range(54):\n",
    "    ConfigRead(alldata[i])\n",
    "    GetData(alldata[i])\n",
    "    DataClean(df)\n",
    "    df_results = ModelSelect(train_x, train_y, test_x, test_y)\n",
    "    df_accuracy = df_accuracy.append(df_results, ignore_index=True)\n",
    "    \n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acute-inflammations-1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acute-inflammations-2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance-scale</th>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banknote-authentication</th>\n",
       "      <td>0.974545</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992727</td>\n",
       "      <td>0.978182</td>\n",
       "      <td>0.996364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood-transfusion-service-center</th>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast-cancer-wisconsin-diagnostic</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast-cancer-wisconsin</th>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>0.985401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast-cancer-wisconsin-prognostic</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car-evaluation</th>\n",
       "      <td>0.806358</td>\n",
       "      <td>0.927746</td>\n",
       "      <td>0.852601</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.170520</td>\n",
       "      <td>0.907514</td>\n",
       "      <td>0.893064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chess-king-rook-vs-king-pawn</th>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.582812</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>climate-model-simulation-crashes</th>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.990741</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>congressional-voting-records</th>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectionist-bench</th>\n",
       "      <td>0.131313</td>\n",
       "      <td>0.792929</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.964646</td>\n",
       "      <td>0.893939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connectionist-bench-sonar</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contraceptive-method-choice</th>\n",
       "      <td>0.549153</td>\n",
       "      <td>0.494915</td>\n",
       "      <td>0.515254</td>\n",
       "      <td>0.522034</td>\n",
       "      <td>0.535593</td>\n",
       "      <td>0.515254</td>\n",
       "      <td>0.569492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit-approval</th>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>0.877863</td>\n",
       "      <td>0.740458</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinder-bands</th>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dermatology</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>echocardiogram</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fertility</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haberman-survival</th>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hayes-roth</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart-disease-cleveland</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hepatitis</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image-segmentation</th>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian-liver-patient</th>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.681034</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ionosphere</th>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.887324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iris</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mammographic-mass</th>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.777108</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.807229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monks-problems-1</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monks-problems-2</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monks-problems-3</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optical-recognition-handwritten-digits</th>\n",
       "      <td>0.487582</td>\n",
       "      <td>0.892810</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.950327</td>\n",
       "      <td>0.722876</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.482353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ozone-level-detection-eight</th>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.927027</td>\n",
       "      <td>0.916216</td>\n",
       "      <td>0.924324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ozone-level-detection-one</th>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>0.981081</td>\n",
       "      <td>0.975676</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>0.983784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parkinsons</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pima-indians-diabetes</th>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>planning-relax</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsar-biodegradation</th>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.800948</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.834123</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeds</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seismic-bumps</th>\n",
       "      <td>0.940039</td>\n",
       "      <td>0.889749</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.941973</td>\n",
       "      <td>0.056093</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.943907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soybean-small</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spambase</th>\n",
       "      <td>0.908795</td>\n",
       "      <td>0.920738</td>\n",
       "      <td>0.823018</td>\n",
       "      <td>0.934853</td>\n",
       "      <td>0.798046</td>\n",
       "      <td>0.960912</td>\n",
       "      <td>0.834962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spect-heart</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectf-heart</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statlog-project-german-credit</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statlog-project-landsat-satellite</th>\n",
       "      <td>0.693348</td>\n",
       "      <td>0.865840</td>\n",
       "      <td>0.897407</td>\n",
       "      <td>0.850056</td>\n",
       "      <td>0.866967</td>\n",
       "      <td>0.908681</td>\n",
       "      <td>0.190530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teaching-assistant-evaluation</th>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thoracic-surgery</th>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thyroid-disease-ann-thyroid</th>\n",
       "      <td>0.992053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>0.936424</td>\n",
       "      <td>0.997351</td>\n",
       "      <td>0.936424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thyroid-disease-new-thyroid</th>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.813953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tic-tac-toe-endgame</th>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall-following-robot-navigation-2</th>\n",
       "      <td>0.852564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989927</td>\n",
       "      <td>0.908425</td>\n",
       "      <td>0.913004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        AdaBoost  Decision Tree       KNN  \\\n",
       "Dataset                                                                     \n",
       "acute-inflammations-1                   1.000000       1.000000  1.000000   \n",
       "acute-inflammations-2                   1.000000       1.000000  1.000000   \n",
       "balance-scale                           0.824000       0.752000  0.872000   \n",
       "banknote-authentication                 0.974545       0.992727  1.000000   \n",
       "blood-transfusion-service-center        0.793333       0.746667  0.740000   \n",
       "breast-cancer-wisconsin-diagnostic      0.894737       0.964912  0.929825   \n",
       "breast-cancer-wisconsin                 0.970803       0.948905  0.985401   \n",
       "breast-cancer-wisconsin-prognostic      0.666667       0.564103  0.589744   \n",
       "car-evaluation                          0.806358       0.927746  0.852601   \n",
       "chess-king-rook-vs-king-pawn            0.925000       0.993750  0.967187   \n",
       "climate-model-simulation-crashes        0.935185       0.944444  0.935185   \n",
       "congressional-voting-records            0.957447       0.957447  0.936170   \n",
       "connectionist-bench                     0.131313       0.792929  0.984848   \n",
       "connectionist-bench-sonar               0.714286       0.714286  0.761905   \n",
       "contraceptive-method-choice             0.549153       0.494915  0.515254   \n",
       "credit-approval                         0.854962       0.854962  0.702290   \n",
       "cylinder-bands                          0.696429       0.750000  0.678571   \n",
       "dermatology                             0.833333       0.972222  0.861111   \n",
       "echocardiogram                          0.846154       0.846154  0.692308   \n",
       "fertility                               0.800000       0.800000  0.750000   \n",
       "haberman-survival                       0.725806       0.645161  0.725806   \n",
       "hayes-roth                              0.444444       0.925926  0.666667   \n",
       "heart-disease-cleveland                 0.500000       0.550000  0.466667   \n",
       "hepatitis                               0.812500       0.750000  0.812500   \n",
       "image-segmentation                      0.404762       0.904762  0.857143   \n",
       "indian-liver-patient                    0.724138       0.655172  0.698276   \n",
       "ionosphere                              0.845070       0.802817  0.830986   \n",
       "iris                                    0.966667       0.966667  1.000000   \n",
       "mammographic-mass                       0.837349       0.801205  0.777108   \n",
       "monks-problems-1                        0.600000       0.760000  0.680000   \n",
       "monks-problems-2                        0.617647       0.647059  0.911765   \n",
       "monks-problems-3                        0.760000       0.760000  0.920000   \n",
       "optical-recognition-handwritten-digits  0.487582       0.892810  0.988235   \n",
       "ozone-level-detection-eight             0.905405       0.927027  0.927027   \n",
       "ozone-level-detection-one               0.983784       0.959459  0.981081   \n",
       "parkinsons                              0.769231       0.794872  0.820513   \n",
       "pima-indians-diabetes                   0.766234       0.668831  0.766234   \n",
       "planning-relax                          0.621622       0.540541  0.594595   \n",
       "qsar-biodegradation                     0.800948       0.800948  0.834123   \n",
       "seeds                                   0.595238       1.000000  0.904762   \n",
       "seismic-bumps                           0.940039       0.889749  0.936170   \n",
       "soybean-small                           1.000000       1.000000  1.000000   \n",
       "spambase                                0.908795       0.920738  0.823018   \n",
       "spect-heart                             0.687500       0.812500  0.812500   \n",
       "spectf-heart                            0.750000       0.812500  0.875000   \n",
       "statlog-project-german-credit           0.710000       0.635000  0.715000   \n",
       "statlog-project-landsat-satellite       0.693348       0.865840  0.897407   \n",
       "teaching-assistant-evaluation           0.419355       0.645161  0.580645   \n",
       "thoracic-surgery                        0.840426       0.819149  0.851064   \n",
       "thyroid-disease-ann-thyroid             0.992053       1.000000  0.940397   \n",
       "thyroid-disease-new-thyroid             0.837209       0.953488  0.953488   \n",
       "tic-tac-toe-endgame                     0.781250       0.958333  1.000000   \n",
       "wall-following-robot-navigation-2       0.852564       1.000000  0.989927   \n",
       "wine                                    0.833333       0.972222  0.750000   \n",
       "\n",
       "                                        Logistic Regression       QDA  \\\n",
       "Dataset                                                                 \n",
       "acute-inflammations-1                              1.000000  1.000000   \n",
       "acute-inflammations-2                              1.000000  1.000000   \n",
       "balance-scale                                      0.832000  0.896000   \n",
       "banknote-authentication                            0.992727  0.978182   \n",
       "blood-transfusion-service-center                   0.746667  0.440000   \n",
       "breast-cancer-wisconsin-diagnostic                 0.964912  0.956140   \n",
       "breast-cancer-wisconsin                            0.985401  1.000000   \n",
       "breast-cancer-wisconsin-prognostic                 0.743590  0.717949   \n",
       "car-evaluation                                     0.907514  0.170520   \n",
       "chess-king-rook-vs-king-pawn                       0.978125  0.582812   \n",
       "climate-model-simulation-crashes                   0.990741  0.925926   \n",
       "congressional-voting-records                       0.957447  0.914894   \n",
       "connectionist-bench                                0.575758  0.893939   \n",
       "connectionist-bench-sonar                          0.761905  0.714286   \n",
       "contraceptive-method-choice                        0.522034  0.535593   \n",
       "credit-approval                                    0.877863  0.740458   \n",
       "cylinder-bands                                     0.767857  0.696429   \n",
       "dermatology                                        0.972222  0.875000   \n",
       "echocardiogram                                     0.769231  0.615385   \n",
       "fertility                                          0.850000  0.850000   \n",
       "haberman-survival                                  0.741935  0.741935   \n",
       "hayes-roth                                         0.407407  0.444444   \n",
       "heart-disease-cleveland                            0.500000  0.483333   \n",
       "hepatitis                                          0.812500  0.875000   \n",
       "image-segmentation                                 0.904762  0.428571   \n",
       "indian-liver-patient                               0.758621  0.560345   \n",
       "ionosphere                                         0.915493  0.830986   \n",
       "iris                                               0.933333  1.000000   \n",
       "mammographic-mass                                  0.807229  0.807229   \n",
       "monks-problems-1                                   0.600000  0.640000   \n",
       "monks-problems-2                                   0.617647  1.000000   \n",
       "monks-problems-3                                   0.920000  0.920000   \n",
       "optical-recognition-handwritten-digits             0.950327  0.722876   \n",
       "ozone-level-detection-eight                        0.929730  0.927027   \n",
       "ozone-level-detection-one                          0.975676  0.983784   \n",
       "parkinsons                                         0.846154  0.948718   \n",
       "pima-indians-diabetes                              0.779221  0.740260   \n",
       "planning-relax                                     0.702703  0.594595   \n",
       "qsar-biodegradation                                0.834123  0.668246   \n",
       "seeds                                              1.000000  1.000000   \n",
       "seismic-bumps                                      0.941973  0.056093   \n",
       "soybean-small                                      1.000000  0.500000   \n",
       "spambase                                           0.934853  0.798046   \n",
       "spect-heart                                        0.687500  0.375000   \n",
       "spectf-heart                                       0.750000  0.500000   \n",
       "statlog-project-german-credit                      0.750000  0.720000   \n",
       "statlog-project-landsat-satellite                  0.850056  0.866967   \n",
       "teaching-assistant-evaluation                      0.645161  0.483871   \n",
       "thoracic-surgery                                   0.840426  0.148936   \n",
       "thyroid-disease-ann-thyroid                        0.952318  0.936424   \n",
       "thyroid-disease-new-thyroid                        1.000000  0.976744   \n",
       "tic-tac-toe-endgame                                0.989583  0.989583   \n",
       "wall-following-robot-navigation-2                  0.908425  0.913004   \n",
       "wine                                               0.944444  1.000000   \n",
       "\n",
       "                                        Random Forest       SVM  \n",
       "Dataset                                                          \n",
       "acute-inflammations-1                        1.000000  1.000000  \n",
       "acute-inflammations-2                        1.000000  1.000000  \n",
       "balance-scale                                0.824000  0.864000  \n",
       "banknote-authentication                      0.996364  1.000000  \n",
       "blood-transfusion-service-center             0.740000  0.726667  \n",
       "breast-cancer-wisconsin-diagnostic           0.956140  0.631579  \n",
       "breast-cancer-wisconsin                      1.000000  0.992701  \n",
       "breast-cancer-wisconsin-prognostic           0.666667  0.717949  \n",
       "car-evaluation                               0.907514  0.893064  \n",
       "chess-king-rook-vs-king-pawn                 0.993750  0.925000  \n",
       "climate-model-simulation-crashes             0.935185  0.925926  \n",
       "congressional-voting-records                 0.978723  0.978723  \n",
       "connectionist-bench                          0.964646  0.893939  \n",
       "connectionist-bench-sonar                    0.738095  0.476190  \n",
       "contraceptive-method-choice                  0.515254  0.569492  \n",
       "credit-approval                              0.885496  0.503817  \n",
       "cylinder-bands                               0.821429  0.714286  \n",
       "dermatology                                  0.986111  0.958333  \n",
       "echocardiogram                               0.769231  0.769231  \n",
       "fertility                                    0.850000  0.850000  \n",
       "haberman-survival                            0.758065  0.774194  \n",
       "hayes-roth                                   0.814815  0.814815  \n",
       "heart-disease-cleveland                      0.516667  0.500000  \n",
       "hepatitis                                    0.937500  0.875000  \n",
       "image-segmentation                           0.928571  0.119048  \n",
       "indian-liver-patient                         0.681034  0.724138  \n",
       "ionosphere                                   0.915493  0.887324  \n",
       "iris                                         0.966667  0.966667  \n",
       "mammographic-mass                            0.765060  0.807229  \n",
       "monks-problems-1                             0.640000  0.600000  \n",
       "monks-problems-2                             0.617647  0.676471  \n",
       "monks-problems-3                             0.880000  0.920000  \n",
       "optical-recognition-handwritten-digits       0.977778  0.482353  \n",
       "ozone-level-detection-eight                  0.916216  0.924324  \n",
       "ozone-level-detection-one                    0.978378  0.983784  \n",
       "parkinsons                                   0.923077  0.820513  \n",
       "pima-indians-diabetes                        0.811688  0.642857  \n",
       "planning-relax                               0.648649  0.702703  \n",
       "qsar-biodegradation                          0.834123  0.810427  \n",
       "seeds                                        0.952381  0.952381  \n",
       "seismic-bumps                                0.936170  0.943907  \n",
       "soybean-small                                1.000000  1.000000  \n",
       "spambase                                     0.960912  0.834962  \n",
       "spect-heart                                  0.750000  0.812500  \n",
       "spectf-heart                                 0.937500  0.375000  \n",
       "statlog-project-german-credit                0.765000  0.705000  \n",
       "statlog-project-landsat-satellite            0.908681  0.190530  \n",
       "teaching-assistant-evaluation                0.741935  0.483871  \n",
       "thoracic-surgery                             0.861702  0.851064  \n",
       "thyroid-disease-ann-thyroid                  0.997351  0.936424  \n",
       "thyroid-disease-new-thyroid                  0.976744  0.813953  \n",
       "tic-tac-toe-endgame                          0.994792  0.937500  \n",
       "wall-following-robot-navigation-2            1.000000  0.946886  \n",
       "wine                                         0.972222  0.388889  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy['Dataset']=alldata\n",
    "df_accuracy = df_accuracy.set_index('Dataset')\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'AdaBoost': 7,\n",
       "         'Decision Tree': 14,\n",
       "         'KNN': 12,\n",
       "         'Logistic Regression': 16,\n",
       "         'QDA': 12,\n",
       "         'Random Forest': 22,\n",
       "         'SVM': 13})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "model=[]\n",
    "for i in range(54):\n",
    "    line = df_accuracy.iloc[i]\n",
    "    model.append(line.index[line == line.max()].tolist()) # For each dataset, find the model with highest accuracy\n",
    "\n",
    "flat_list = [item for sublist in model for item in sublist]\n",
    "Counter(flat_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFTCAYAAAApyvfdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqEQCPSKiEv8fFSwVnG9FhzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f93646e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "labels, values = zip(*Counter(flat_list).items())\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 0.5\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes, labels,rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
